# MobileNet V2

### Github Link
```https://github.com/DYBCyrus/OnnxPytorchModels/tree/master/MobileNet```

### Onnx File Name
```mobilenetv2-7```

### Include Training and Inference
```True```

### Python/Module File name
```mobilenetv2```

### Module Class Name
```MobileNetV2```

### Model Name
```mobile-net-v2```

### Category Name
```Computer Vision```

### Tasks
```Classification, Mobile Vision Applications```

### Cover Image
```https://miro.medium.com/max/1016/1*5iA55983nBMlQn9f6ICxKg.png```

### Input Description
All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (N x 3 x H x W), 
where N is the batch size, and H and W are expected to be at least 224. The inference was done using jpeg image.

### Preprocessing Description
The images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]. 
The transformation should preferrably happen at preprocessing. Sample code:
```python
from torchvision import transforms

def preprocess(img):   
    '''
    The function takes path to an image and returns processed tensor
    '''
    transform_fn = transforms.Compose([
    transforms.Resize(224),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    img = transform_fn(img)
    img = img.expand_dims(axis=0) # batchify
    
    return img
```

### Output Description
The model outputs image scores for each of the 1000 classes of ImageNet.

### Postprocessing Description
The post-processing involves calculating the softmax probablility scores for each class and sorting them to report the most probable classes.
Sample code:
```python
import numpy as np
import torch.nn as nn

# Post-processing function for ImageNet models
def postprocess(scores): 
    '''
    The function takes scores generated by the network and returns the class IDs in decreasing order
    of probability
    '''
    # if inferenced on cuda, convert it back on cpu first
    # prob = nn.Softmax(scores).to('cpu').numpy()
    prob = nn.Softmax(scores).numpy()
    prob = np.squeeze(prob)
    a = np.argsort(prob)[::-1]
    return a
```

### Hyperparameter Description
```
learning rate = 0.045, optimizer = SGD, batch size = 40, total number of epochs = 480, weight decay = 0.00004, 
momentum = 0.9, learning rate decay = 0.98, learning rate decay period = 1
```

### Dataset Name
```ImageNet```

### Dataset URL
```http://www.image-net.org/challenges/LSVRC/2012/```

### Paper Authors
```Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen```

### Paper Link
```https://arxiv.org/pdf/1801.04381.pdf```

### Evaluation Metrics
```accuracy```

### Evaluation Results
```Top-1 accuracy: 70.94%, Top-5 accuracy: 89.99%```

### Training/Validation Loss Graph
```N/A```
